{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTfq3gp6WC5KXNfeDGx+T5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basudevm23/ML-Trial-and-Error/blob/main/SENTIMENT_ANALYSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis\n",
        "input will have text data\n",
        "output will have 0 or 1 as positive or negative sentiment\n",
        "\n",
        "we will form the vocab, each word is provided a vector\n",
        "size different\n",
        "we do padding\n",
        "first we convert text to vectors"
      ],
      "metadata": {
        "id": "mhoZgaI-e67p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "docs = ['go india',\n",
        "\t\t'india india',\n",
        "\t\t'hip hip hurray',\n",
        "\t\t'jeetega bhai jeetega india jeetega',\n",
        "\t\t'bharat mata ki jai',\n",
        "\t\t'kohli kohli',\n",
        "\t\t'sachin sachin',\n",
        "\t\t'dhoni dhoni',\n",
        "\t\t'modi ji ki jai',\n",
        "\t\t'inquilab zindabad']"
      ],
      "metadata": {
        "id": "xGL9tN6ufLwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<nothing>')"
      ],
      "metadata": {
        "id": "BZQPzXCGfp3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef812bb1",
        "outputId": "ed8851f8-f05e-4c34-8b43-f580fdb01097"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "XMVvifLQEgcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KarQMSWjEp3p",
        "outputId": "edd40105-de62-444e-8bab-ddd32848c33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bedejke_Esu-",
        "outputId": "e2354fd5-24fa-46e3-bda5-e4bc48d71389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('go', 1),\n",
              "             ('india', 4),\n",
              "             ('hip', 2),\n",
              "             ('hurray', 1),\n",
              "             ('jeetega', 3),\n",
              "             ('bhai', 1),\n",
              "             ('bharat', 1),\n",
              "             ('mata', 1),\n",
              "             ('ki', 2),\n",
              "             ('jai', 2),\n",
              "             ('kohli', 2),\n",
              "             ('sachin', 2),\n",
              "             ('dhoni', 2),\n",
              "             ('modi', 1),\n",
              "             ('ji', 1),\n",
              "             ('inquilab', 1),\n",
              "             ('zindabad', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlLAkie3E1-_",
        "outputId": "4fedc9ca-ba45-4d92-9a5b-c7b39d346508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 2],\n",
              " [2, 2],\n",
              " [4, 4, 11],\n",
              " [3, 12, 3, 2, 3],\n",
              " [13, 14, 5, 6],\n",
              " [7, 7],\n",
              " [8, 8],\n",
              " [9, 9],\n",
              " [15, 16, 5, 6],\n",
              " [17, 18]]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "D25_oeKSFBPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences, padding = 'post')"
      ],
      "metadata": {
        "id": "nn_XbtjrFId5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77nS5oDWFQeJ",
        "outputId": "c298e480-37de-4814-f784-21020ff15bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  2,  0,  0,  0],\n",
              "       [ 2,  2,  0,  0,  0],\n",
              "       [ 4,  4, 11,  0,  0],\n",
              "       [ 3, 12,  3,  2,  3],\n",
              "       [13, 14,  5,  6,  0],\n",
              "       [ 7,  7,  0,  0,  0],\n",
              "       [ 8,  8,  0,  0,  0],\n",
              "       [ 9,  9,  0,  0,  0],\n",
              "       [15, 16,  5,  6,  0],\n",
              "       [17, 18,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(19, output_dim=2, input_length=5))\n",
        "\n",
        "model.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "7WtBP05kQ6yF",
        "outputId": "9f37598e-4287-404d-ed29-5d85b30f20bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <Sequential name=sequential_6, built=False>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.models.model.Model.summary</b><br/>def summary(line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/keras/src/models/model.py</a>Prints a string summary of the network.\n",
              "\n",
              "Args:\n",
              "    line_length: Total length of printed lines\n",
              "        (e.g. set this to adapt the display to different\n",
              "        terminal window sizes).\n",
              "    positions: Relative or absolute positions of log elements\n",
              "        in each line. If not provided, becomes\n",
              "        `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n",
              "    print_fn: Print function to use. By default, prints to `stdout`.\n",
              "        If `stdout` doesn&#x27;t work in your environment, change to `print`.\n",
              "        It will be called on each line of the summary.\n",
              "        You can set it to a custom function\n",
              "        in order to capture the string summary.\n",
              "    expand_nested: Whether to expand the nested models.\n",
              "        Defaults to `False`.\n",
              "    show_trainable: Whether to show if a layer is trainable.\n",
              "        Defaults to `False`.\n",
              "    layer_range: a list or tuple of 2 strings,\n",
              "        which is the starting layer name and ending layer name\n",
              "        (both inclusive) indicating the range of layers to be printed\n",
              "        in summary. It also accepts regex patterns instead of exact\n",
              "        names. In this case, the start predicate will be\n",
              "        the first element that matches `layer_range[0]`\n",
              "        and the end predicate will be the last element\n",
              "        that matches `layer_range[1]`.\n",
              "        By default `None` considers all layers of the model.\n",
              "\n",
              "Raises:\n",
              "    ValueError: if `summary()` is called before the model is built.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 218);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam', 'accuracy')"
      ],
      "metadata": {
        "id": "sDornogkSTOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred= model.predict(sequences)\n",
        "print(pred)\n",
        "#each word is represented by 1x2 vector, even zeroes have their vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWRzyN5jSXxL",
        "outputId": "4e3bf52e-dd05-459b-915f-603a41ac6763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "[[[ 0.02140016 -0.00106201]\n",
            "  [-0.04037691 -0.03077224]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[-0.04037691 -0.03077224]\n",
            "  [-0.04037691 -0.03077224]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[ 0.04797414  0.04867804]\n",
            "  [ 0.04797414  0.04867804]\n",
            "  [-0.02417874 -0.00494383]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[ 0.02723909 -0.04814107]\n",
            "  [ 0.02862498  0.03219802]\n",
            "  [ 0.02723909 -0.04814107]\n",
            "  [-0.04037691 -0.03077224]\n",
            "  [ 0.02723909 -0.04814107]]\n",
            "\n",
            " [[ 0.01756282  0.04139617]\n",
            "  [ 0.00447085 -0.04701031]\n",
            "  [ 0.02684193  0.01211152]\n",
            "  [-0.01051266  0.03010868]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[-0.02367277  0.0363141 ]\n",
            "  [-0.02367277  0.0363141 ]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[-0.00699456  0.0267023 ]\n",
            "  [-0.00699456  0.0267023 ]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[-0.03686481  0.00044836]\n",
            "  [-0.03686481  0.00044836]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[ 0.03094563 -0.00199568]\n",
            "  [ 0.04927397 -0.02348901]\n",
            "  [ 0.02684193  0.01211152]\n",
            "  [-0.01051266  0.03010868]\n",
            "  [ 0.04098724  0.00103771]]\n",
            "\n",
            " [[ 0.01662203 -0.03480332]\n",
            "  [ 0.04345486  0.00154227]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]\n",
            "  [ 0.04098724  0.00103771]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inmd sentiment classfication dataset\n",
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Flatten"
      ],
      "metadata": {
        "id": "OoBKCNvnFXQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "7S-QbUC3FujP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WidcUCh3F9t4",
        "outputId": "8506ea0b-48da-4b58-8f35-d16f37755ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDe_ZGEqGD8L",
        "outputId": "8997b232-43d0-41d5-8253-efe883db5c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train, padding = 'post', maxlen=50)\n",
        "X_test = pad_sequences(X_test, padding = 'post', maxlen=50)"
      ],
      "metadata": {
        "id": "BPUQneWWGGU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Koem8tcKGX81",
        "outputId": "12b72e82-8ed8-429e-a76b-720d6610d129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lJEp38fGcb2",
        "outputId": "dbb295be-3005-4615-b286-a0fd9eb2ac41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,\n",
              "         21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,\n",
              "         36,   28,  224,   92,   25,  104,    4,  226,   65,   16,   38,\n",
              "       1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,\n",
              "         15,   16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(SimpleRNN(32, input_shape = (50, 1), return_sequences=False))\n",
        "# model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# model.summary\n",
        "\n",
        "#10000, 2, 50\n",
        "# here 10000 is the vocabulary, 2 is the dimension of the output, and 50 is the input size\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 2, input_length=50))\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "L5sJmMUxGe4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "50 time steps will be taking place\n",
        "total weights=1088 in the simple rnn\n",
        "total weights =33 in dense rnn\n",
        "\n",
        "return sequences are kept false, becoz the output at the end of each time step is fed into the next time step\n",
        "Ot-1 is used for Ot for finding new prediction value\n"
      ],
      "metadata": {
        "id": "mnO50rk8H4OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp4aLVaaK8zj",
        "outputId": "60109642-937a-466c-8775-7a50ee7614e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 28ms/step - accuracy: 0.5258 - loss: 0.6903 - val_accuracy: 0.5733 - val_loss: 0.6666\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15ms/step - accuracy: 0.6360 - loss: 0.6363 - val_accuracy: 0.6276 - val_loss: 0.6362\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.7604 - loss: 0.4922 - val_accuracy: 0.7721 - val_loss: 0.4775\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8658 - loss: 0.3227 - val_accuracy: 0.7948 - val_loss: 0.4867\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9001 - loss: 0.2509 - val_accuracy: 0.7829 - val_loss: 0.4868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78b76b86f2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}